{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b234ad",
   "metadata": {},
   "source": [
    "# The Epitome of Salt's Sunrise Show: Avatar: The Last Airbender (TLA)\n",
    "## Author: Kevin Brar\n",
    "## Guests: Nate, Josh, Jon, Michael\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de22479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raters\n",
    "raters = ['Kevin', 'Nate', \"Jon\", 'Josh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f03d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/{rater}.csv\n",
      "data/{rater}.csv\n",
      "data/{rater}.csv\n",
      "data/{rater}.csv\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 147, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m eos.rename(columns={\u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m: raters[\u001b[32m0\u001b[39m]}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rater \u001b[38;5;129;01min\u001b[39;00m raters[\u001b[32m1\u001b[39m:]:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     rater_data = \u001b[43mread_ratings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrater\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     rater_ratings = rater_data[[\u001b[33m'\u001b[39m\u001b[33mName\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m]].rename(columns={\u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m: rater})\n\u001b[32m     59\u001b[39m     eos = pd.merge(eos, rater_ratings, on=\u001b[33m'\u001b[39m\u001b[33mName\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mread_ratings\u001b[39m\u001b[34m(rater)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdata/\u001b[39m\u001b[38;5;132;01m{rater}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrater\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: Could not find file data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrater\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv. Please make sure it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms in a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m subfolder.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kevbot\\anaconda3\\envs\\machineLearning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kevbot\\anaconda3\\envs\\machineLearning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kevbot\\anaconda3\\envs\\machineLearning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kevbot\\anaconda3\\envs\\machineLearning\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 5 fields in line 147, saw 7\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "def read_ratings(rater):\n",
    "    try:\n",
    "        print('data/{rater}.csv')\n",
    "        df = pd.read_csv(f'data/{rater}.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find file data/{rater}.csv. Please make sure it's in a 'data' subfolder.\")\n",
    "        return pd.DataFrame(columns=['Name', 'Rarity', 'Color', 'Rating'])\n",
    "        \n",
    "    if 'Name' in df.columns:\n",
    "        df['Name'] = df['Name'].str.strip()\n",
    "    else:\n",
    "        print(f\"Warning: 'Name' column not found in {rater}.csv\")\n",
    "        df['Name'] = pd.NA \n",
    "        \n",
    "    rarity_map = {\n",
    "        'common': 'C',\n",
    "        'uncommon': 'U',\n",
    "        'rare': 'R',\n",
    "        'mythic': 'M'\n",
    "    }\n",
    "    if 'Rarity' in df.columns:\n",
    "        df['Rarity'] = df['Rarity'].map(rarity_map)\n",
    "    else:\n",
    "        print(f\"Warning: 'Rarity' column not found in {rater}.csv\")\n",
    "        df['Rarity'] = pd.NA \n",
    "\n",
    "    if 'Color' in df.columns:\n",
    "        df['Color'] = df['Color'].fillna('C')\n",
    "        df['Color'] = df['Color'].apply(lambda x: 'M' if isinstance(x, str) and len(x) > 1 else x)\n",
    "    else:\n",
    "        print(f\"Warning: 'Color' column not found in {rater}.csv\")\n",
    "        df['Color'] = pd.NA \n",
    "        \n",
    "    if 'Rating' not in df.columns:\n",
    "        print(f\"Warning: 'Rating' column not found in {rater}.csv\")\n",
    "        df['Rating'] = pd.NA \n",
    "\n",
    "    return df[['Name', 'Rarity', 'Color', 'Rating']]\n",
    "\n",
    "tier_num = {'G':0., 'D-': 1., 'D': 2., 'D+': 3., \n",
    "            'C-': 4., 'C': 5., 'C+': 6., 'B-': 7., \n",
    "            'B': 8., 'B+': 9., 'A-': 10., 'A': 11., \n",
    "            'A+': 12.}\n",
    "\n",
    "if not raters:\n",
    "    print(\"Error: 'raters' list is empty. Please define it.\")\n",
    "else:\n",
    "    eos = read_ratings(raters[0])\n",
    "    eos.rename(columns={'Rating': raters[0]}, inplace=True)\n",
    "\n",
    "    for rater in raters[1:]:\n",
    "        rater_data = read_ratings(rater)\n",
    "        \n",
    "        rater_ratings = rater_data[['Name', 'Rating']].rename(columns={'Rating': rater})\n",
    "        \n",
    "        eos = pd.merge(eos, rater_ratings, on='Name', how='outer')\n",
    "\n",
    "    print(\"--- Unrated Card Analysis ---\")\n",
    "    all_cards_rated = True\n",
    "    for rater in raters:\n",
    "        unrated_cards = eos[eos[rater].isnull()]['Name']\n",
    "        if unrated_cards.empty:\n",
    "            print(f\"All cards were rated by {rater}.\")\n",
    "        else:\n",
    "            all_cards_rated = False\n",
    "            print(f\"\\nCards NOT rated by {rater}:\")\n",
    "            print(unrated_cards.to_string(index=False))\n",
    "            \n",
    "    if all_cards_rated and not eos[raters[0]].isnull().any():\n",
    "        print(\"All raters rated all cards. Perfect match.\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "    for rater in raters:\n",
    "        eos[f'{rater}_num'] = eos[rater].map(tier_num)\n",
    "\n",
    "    rater_num_cols = [f'{rater}_num' for rater in raters]\n",
    "    eos_clean = eos.dropna(subset=rater_num_cols).copy()\n",
    "\n",
    "eos = eos_clean\n",
    "eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f09d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Average Rating by Color Pair (Sorted) ---\n",
      "Colors: W & G - Average Rating: 5.57\n",
      "Colors: W & U - Average Rating: 5.5\n",
      "Colors: W & R - Average Rating: 5.46\n",
      "Colors: W & B - Average Rating: 5.4\n",
      "Colors: U & G - Average Rating: 5.26\n",
      "Colors: R & G - Average Rating: 5.23\n",
      "Colors: B & G - Average Rating: 5.17\n",
      "Colors: R & U - Average Rating: 5.16\n",
      "Colors: B & U - Average Rating: 5.1\n",
      "Colors: R & B - Average Rating: 5.07\n"
     ]
    }
   ],
   "source": [
    "colors = ['W', 'R', 'B', 'U', 'G']\n",
    "\n",
    "# Calculate the 'Group' average (mean rating) for each card\n",
    "# This line is corrected from your screenshot\n",
    "eos['Group'] = eos[[rater + '_num' for rater in raters]].sum(axis=1) / len(raters)\n",
    "\n",
    "color_pairs = list(combinations(colors, 2))\n",
    "color_pair_scores = {}\n",
    "\n",
    "for pair in color_pairs:\n",
    "    color1, color2 = pair\n",
    "    \n",
    "    # Find all rows that match *either* color1 or color2\n",
    "    pair_rows = eos[(eos['Color'] == color1) | (eos['Color'] == color2)] \n",
    "    \n",
    "    total_score = 0.0 # Default score if no cards are found\n",
    "    if len(pair_rows) > 0:\n",
    "        # Calculate the average AND round it to 2 decimal places\n",
    "        total_score = round(pair_rows['Group'].sum() / len(pair_rows), 2)\n",
    "    \n",
    "    color_pair_scores[pair] = total_score\n",
    "\n",
    "# --- NEW: Sort into a LIST of tuples, not a dict ---\n",
    "sorted_color_pair_list = sorted(color_pair_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# This will print the clean, sorted list you want\n",
    "print(\"--- Average Rating by Color Pair (Sorted) ---\")\n",
    "for x in sorted_color_pair_list:\n",
    "    print(f\"Colors: {x[0][0]} & {x[0][1]} - Average Rating: {x[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e57656",
   "metadata": {},
   "source": [
    "## Top and Bottom Commons and Uncommons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24be4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 3 Commons by Color ---\n",
      "                      Name Color    Group\n",
      "                  Sold Out     B 6.666667\n",
      "           Swampsnare Trap     B 5.000000\n",
      "         Callous Inspector     B 4.666667\n",
      "            Aang's Journey     C 4.000000\n",
      "              Rumble Arena     C 4.000000\n",
      " Barrels of Blasting Jelly     C 3.333333\n",
      "              Rocky Rebuke     G 6.666667\n",
      "                Badgermole     G 6.000000\n",
      "             Ostrich-Horse     G 6.000000\n",
      "            Serpent's Pass     M 5.666667\n",
      "          Sun-Blessed Peak     M 5.666667\n",
      "       Airship Engine Room     M 5.333333\n",
      "          Lightning Strike     R 8.000000\n",
      "        Firebending Lesson     R 6.333333\n",
      "  Treetop Freedom Fighters     R 6.333333\n",
      "Forecasting Fortune Teller     U 6.666667\n",
      "         Rowdy Snowballers     U 5.333333\n",
      "             Iguana Parrot     U 5.000000\n",
      "           Kyoshi Warriors     W 6.333333\n",
      "        Path to Redemption     W 5.666667\n",
      "         Airbending Lesson     W 5.333333\n"
     ]
    }
   ],
   "source": [
    "eos_commons = eos[eos['Rarity'] == 'C']\n",
    "top_cards_by_color = eos_commons.groupby('Color').apply(\n",
    "    lambda x: x.nlargest(3, 'Group'), \n",
    "    include_groups=False\n",
    ").reset_index()\n",
    "\n",
    "print(\"--- Top 3 Commons by Color ---\")\n",
    "print(top_cards_by_color[['Name', 'Color', 'Group']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05fd5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name Color    Group\n",
      "      Azula, On the Hunt     B 7.000000\n",
      "           Heartless Act     B 7.000000\n",
      "           Epic Downfall     B 6.333333\n",
      "            Meteor Sword     C 5.333333\n",
      "     Fire Nation Warship     C 4.333333\n",
      "     White Lotus Hideout     C 4.333333\n",
      "  Toph, the Blind Bandit     G 8.000000\n",
      "          Allies at Last     G 7.666667\n",
      "   Earth Kingdom General     G 6.666667\n",
      "    Suki, Kyoshi Warrior     M 7.333333\n",
      "           Dai Li Agents     M 7.000000\n",
      "            Sun Warriors     M 7.000000\n",
      "  The Cave of Two Lovers     R 7.333333\n",
      "    Combustion Technique     R 7.000000\n",
      "          Combustion Man     R 6.666667\n",
      " Katara, Bending Prodigy     U 7.666667\n",
      "        Knowledge Seeker     U 7.333333\n",
      " Benevolent River Spirit     U 7.000000\n",
      "    Earth Kingdom Jailer     W 7.666667\n",
      "Aang, the Last Airbender     W 7.333333\n",
      "          Master Piandao     W 7.000000\n",
      "--- Top 3 Uncommons by Color ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevbot\\AppData\\Local\\Temp\\ipykernel_18328\\1248522804.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_cards_by_color = eos_uncommons.groupby('Color').apply(lambda x: x.nlargest(3, 'Group')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "eos_uncommons = eos[eos['Rarity'] == 'U']\n",
    "top_cards_by_color = eos_uncommons.groupby('Color').apply(lambda x: x.nlargest(3, 'Group')).reset_index(drop=True)\n",
    "print(top_cards_by_color[['Name', 'Color', 'Group']].to_string(index=False))\n",
    "print(\"--- Top 3 Uncommons by Color ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc24eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bottom 3 Commons by Color ---\n",
      "                     Name Color    Group\n",
      "               Hog-Monkey     B 2.666667\n",
      "        Azula Always Lies     B 3.000000\n",
      "      Foggy Swamp Hunters     B 3.000000\n",
      "        Kyoshi Battle Fan     C 3.000000\n",
      "Barrels of Blasting Jelly     C 3.333333\n",
      "       Bender's Waterskin     C 3.333333\n",
      "              Turtle-Duck     G 1.333333\n",
      "         Cycle of Renewal     G 2.666667\n",
      "      Earthbending Lesson     G 2.666667\n",
      "            Platypus-Bear     M 2.000000\n",
      "                  Cat-Owl     M 3.666667\n",
      "        Vindictive Warden     M 4.000000\n",
      "       Fire Nation Cadets     R 3.000000\n",
      "       Fire Nation Raider     R 3.333333\n",
      "                 Mountain     R 3.333333\n",
      "     Flexible Waterbender     U 3.000000\n",
      "            Geyser Leaper     U 3.000000\n",
      "            Otter-Penguin     U 3.000000\n",
      "     Curious Farm Animals     W 3.000000\n",
      "                   Plains     W 3.333333\n",
      "                 Yip Yip!     W 3.333333\n"
     ]
    }
   ],
   "source": [
    "eos_commons = eos[eos['Rarity'] == 'C']\n",
    "top_cards_by_color = eos_commons.groupby('Color').apply(\n",
    "    lambda x: x.nsmallest(3, 'Group'), \n",
    "    include_groups=False\n",
    ").reset_index()\n",
    "\n",
    "print(\"--- Bottom 3 Commons by Color ---\")\n",
    "print(top_cards_by_color[['Name', 'Color', 'Group']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289a29fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bottom 3 Uncommons by Color ---\n",
      "                         Name Color    Group\n",
      "          Northern Air Temple     B 1.333333\n",
      "          Buzzard-Wasp Colony     B 3.000000\n",
      "       Lo and Li, Twin Tutors     B 3.000000\n",
      "             Trusty Boomerang     C 2.000000\n",
      "                Energybending     C 4.000000\n",
      "          Fire Nation Warship     C 4.333333\n",
      "          Kyoshi Island Plaza     G 1.333333\n",
      "               Sparring Dummy     G 3.000000\n",
      "             Invasion Tactics     G 4.000000\n",
      "Professor Zei, Anthropologist     M 3.666667\n",
      "             Air Nomad Legacy     M 4.000000\n",
      "                 Tolls of War     M 5.000000\n",
      "       Crescent Island Temple     R 2.333333\n",
      "             Price of Freedom     R 2.666667\n",
      "           Jet's Brainwashing     R 3.333333\n",
      "                 Master Pakku     U 2.333333\n",
      "         Teo, Spirited Glider     U 3.333333\n",
      "                Sokka's Haiku     U 4.000000\n",
      "           Vengeful Villagers     W 3.333333\n",
      "               Fancy Footwork     W 4.000000\n",
      "          Southern Air Temple     W 4.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevbot\\AppData\\Local\\Temp\\ipykernel_18328\\3723759558.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_cards_by_color = eos_uncommons.groupby('Color').apply(lambda x: x.nsmallest(3, 'Group')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "eos_uncommons = eos[eos['Rarity'] == 'U']\n",
    "top_cards_by_color = eos_uncommons.groupby('Color').apply(lambda x: x.nsmallest(3, 'Group')).reset_index(drop=True)\n",
    "print(\"--- Bottom 3 Uncommons by Color ---\")\n",
    "print(top_cards_by_color[['Name', 'Color', 'Group']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18dd22b",
   "metadata": {},
   "source": [
    "## Goodest Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00e0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name    Group\n",
      "The Walls of Ba Sing Se 0.000000\n",
      "    Northern Air Temple 1.333333\n",
      "    Kyoshi Island Plaza 1.333333\n"
     ]
    }
   ],
   "source": [
    "sorted_eos = eos.sort_values(by='Group', ascending=True).copy()\n",
    "print(sorted_eos[['Name', 'Group']][:3].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a61a82",
   "metadata": {},
   "source": [
    "## Highest Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e313287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Name  Variance\n",
      "                           Avatar Destiny 13.000000\n",
      "                    Phoenix Fleet Airship 12.333333\n",
      "                         Invasion Tactics 12.000000\n",
      "                        Iroh, Grand Lotus 12.000000\n",
      "                                    Swamp 10.333333\n",
      "                         Zuko, Conflicted 10.333333\n",
      "    The Legend of Kyoshi // Avatar Kyoshi  9.333333\n",
      "                          Fated Firepower  9.333333\n",
      "The Legend of Yangchen // Avatar Yangchen  9.000000\n",
      "                                   Island  8.333333\n",
      "                                   Plains  8.333333\n",
      "                                 Mountain  8.333333\n",
      "                                   Forest  8.333333\n",
      "                               Tiger-Seal  8.333333\n",
      "                             Realm of Koh  7.000000\n"
     ]
    }
   ],
   "source": [
    "eos['Variance'] = eos[[rater + '_num' for rater in raters]].var(axis=1)\n",
    "sorted_eos = eos.sort_values(by='Variance', ascending=False).copy()\n",
    "print(sorted_eos[['Name', 'Variance']][:15].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48075da",
   "metadata": {},
   "source": [
    "## Hottest takes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a22480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name  Kevin_Hot_Take\n",
      "    Iroh, Grand Lotus             6.0\n",
      "       Avatar Destiny             6.0\n",
      "Phoenix Fleet Airship             5.5\n",
      "\n",
      "                                 Name  Nate_Hot_Take\n",
      "                     Invasion Tactics            6.0\n",
      "                     Zuko, Conflicted            5.5\n",
      "The Legend of Kyoshi // Avatar Kyoshi            5.0\n",
      "\n",
      "               Name  Jon_Hot_Take\n",
      "    Fated Firepower           5.0\n",
      "         Tiger-Seal           5.0\n",
      "Wandering Musicians           4.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rater in raters:\n",
    "    other_raters = [col for col in eos.columns if col.endswith('_num') and col != f'{rater}_num']\n",
    "    eos[f'{rater}_mean'] = eos[other_raters].mean(axis=1)\n",
    "\n",
    "for rater in raters:\n",
    "    eos[f'{rater}_Hot_Take'] = abs(eos[f'{rater}_num'] - eos[f'{rater}_mean'])\n",
    "\n",
    "for rater in raters:\n",
    "    sorted_eos = eos.sort_values(by= rater + '_Hot_Take', ascending=False).copy()\n",
    "    print(sorted_eos[['Name', rater + '_Hot_Take']][:3].to_string(index=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb03f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
